{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match searches with bookings\n",
    "\n",
    "- For every search in the searches file, find out whether the search ended up in a booking or not (using the info in the bookings file). For instance, search and booking origin and destination should match. \n",
    "\n",
    "- For the bookings file, origin and destination are the columns dep_port and arr_port, respectively. \n",
    "\n",
    "- Generate a CSV file with the search data, and an additional field, containing 1 if the search ended up in a booking, and 0 otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEPS TO FOLLOW\n",
    "\n",
    "1) Understand the data\n",
    "\n",
    "2) Quick Notes\n",
    "\n",
    "3) Action plan\n",
    "\n",
    "4) Plan Execution with sample\n",
    "    \n",
    "5) Plan Execution with all data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Lets check what we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_date</th>\n",
       "      <th>source</th>\n",
       "      <th>pos_ctry</th>\n",
       "      <th>pos_iata</th>\n",
       "      <th>pos_oid</th>\n",
       "      <th>rloc</th>\n",
       "      <th>cre_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>distance</th>\n",
       "      <th>dep_port</th>\n",
       "      <th>dep_city</th>\n",
       "      <th>dep_ctry</th>\n",
       "      <th>arr_port</th>\n",
       "      <th>arr_city</th>\n",
       "      <th>arr_ctry</th>\n",
       "      <th>lst_port</th>\n",
       "      <th>lst_city</th>\n",
       "      <th>lst_ctry</th>\n",
       "      <th>brd_port</th>\n",
       "      <th>brd_city</th>\n",
       "      <th>brd_ctry</th>\n",
       "      <th>off_port</th>\n",
       "      <th>off_city</th>\n",
       "      <th>off_ctry</th>\n",
       "      <th>mkt_port</th>\n",
       "      <th>mkt_city</th>\n",
       "      <th>mkt_ctry</th>\n",
       "      <th>intl</th>\n",
       "      <th>route</th>\n",
       "      <th>carrier</th>\n",
       "      <th>bkg_class</th>\n",
       "      <th>cab_class</th>\n",
       "      <th>brd_time</th>\n",
       "      <th>off_time</th>\n",
       "      <th>pax</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>oid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-03-05 00:00:00</td>\n",
       "      <td>1A</td>\n",
       "      <td>DE</td>\n",
       "      <td>a68dd7ae953c8acfb187a1af2dcbe123</td>\n",
       "      <td>1a11ae49fcbf545fd2afc1a24d88d2b7</td>\n",
       "      <td>ea65900e72d71f4626378e2ebd298267</td>\n",
       "      <td>2013-02-22 00:00:00</td>\n",
       "      <td>1708</td>\n",
       "      <td>0</td>\n",
       "      <td>ZRH</td>\n",
       "      <td>ZRH</td>\n",
       "      <td>CH</td>\n",
       "      <td>LHR</td>\n",
       "      <td>LON</td>\n",
       "      <td>GB</td>\n",
       "      <td>ZRH</td>\n",
       "      <td>ZRH</td>\n",
       "      <td>CH</td>\n",
       "      <td>LHR</td>\n",
       "      <td>LON</td>\n",
       "      <td>GB</td>\n",
       "      <td>ZRH</td>\n",
       "      <td>ZRH</td>\n",
       "      <td>CH</td>\n",
       "      <td>LHRZRH</td>\n",
       "      <td>LONZRH</td>\n",
       "      <td>CHGB</td>\n",
       "      <td>1</td>\n",
       "      <td>LHRZRH</td>\n",
       "      <td>VI</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-03-07 08:50:00</td>\n",
       "      <td>2013-03-07 11:33:37</td>\n",
       "      <td>-1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   act_date             source  pos_ctry                          pos_iata  \\\n",
       "0  2013-03-05 00:00:00  1A      DE        a68dd7ae953c8acfb187a1af2dcbe123   \n",
       "\n",
       "                          pos_oid                      rloc            \\\n",
       "0  1a11ae49fcbf545fd2afc1a24d88d2b7  ea65900e72d71f4626378e2ebd298267   \n",
       "\n",
       "   cre_date             duration  distance  dep_port  dep_city  dep_ctry  \\\n",
       "0  2013-02-22 00:00:00      1708         0  ZRH       ZRH       CH         \n",
       "\n",
       "   arr_port  arr_city  arr_ctry  lst_port  lst_city  lst_ctry  brd_port  \\\n",
       "0  LHR       LON       GB        ZRH       ZRH       CH        LHR        \n",
       "\n",
       "   brd_city  brd_ctry  off_port  off_city  off_ctry  mkt_port  mkt_city  \\\n",
       "0  LON       GB        ZRH       ZRH       CH        LHRZRH    LONZRH     \n",
       "\n",
       "   mkt_ctry  intl  route           carrier  bkg_class  cab_class  \\\n",
       "0  CHGB         1  LHRZRH               VI  T          Y           \n",
       "\n",
       "   brd_time             off_time             pax  year  month  oid        \n",
       "0  2013-03-07 08:50:00  2013-03-07 11:33:37   -1  2013      3  NULL       "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookings_check = pd.read_csv('bookings.csv', sep= '^', error_bad_lines=False, nrows=1)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "bookings_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>TxnCode</th>\n",
       "      <th>OfficeID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>RoundTrip</th>\n",
       "      <th>NbSegments</th>\n",
       "      <th>Seg1Departure</th>\n",
       "      <th>Seg1Arrival</th>\n",
       "      <th>Seg1Date</th>\n",
       "      <th>Seg1Carrier</th>\n",
       "      <th>Seg1BookingCode</th>\n",
       "      <th>Seg2Departure</th>\n",
       "      <th>Seg2Arrival</th>\n",
       "      <th>Seg2Date</th>\n",
       "      <th>Seg2Carrier</th>\n",
       "      <th>Seg2BookingCode</th>\n",
       "      <th>Seg3Departure</th>\n",
       "      <th>Seg3Arrival</th>\n",
       "      <th>Seg3Date</th>\n",
       "      <th>Seg3Carrier</th>\n",
       "      <th>Seg3BookingCode</th>\n",
       "      <th>Seg4Departure</th>\n",
       "      <th>Seg4Arrival</th>\n",
       "      <th>Seg4Date</th>\n",
       "      <th>Seg4Carrier</th>\n",
       "      <th>Seg4BookingCode</th>\n",
       "      <th>Seg5Departure</th>\n",
       "      <th>Seg5Arrival</th>\n",
       "      <th>Seg5Date</th>\n",
       "      <th>Seg5Carrier</th>\n",
       "      <th>Seg5BookingCode</th>\n",
       "      <th>Seg6Departure</th>\n",
       "      <th>Seg6Arrival</th>\n",
       "      <th>Seg6Date</th>\n",
       "      <th>Seg6Carrier</th>\n",
       "      <th>Seg6BookingCode</th>\n",
       "      <th>From</th>\n",
       "      <th>IsPublishedForNeg</th>\n",
       "      <th>IsFromInternet</th>\n",
       "      <th>IsFromVista</th>\n",
       "      <th>TerminalID</th>\n",
       "      <th>InternetOffice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>20:25:57</td>\n",
       "      <td>MPT</td>\n",
       "      <td>624d8c3ac0b3a7ca03e3c167e0f48327</td>\n",
       "      <td>DE</td>\n",
       "      <td>TXL</td>\n",
       "      <td>AUH</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>TXL</td>\n",
       "      <td>AUH</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>D2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AUH</td>\n",
       "      <td>TXL</td>\n",
       "      <td>2013-02-02</td>\n",
       "      <td>D2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time TxnCode                          OfficeID Country  \\\n",
       "0  2013-01-01  20:25:57     MPT  624d8c3ac0b3a7ca03e3c167e0f48327      DE   \n",
       "\n",
       "  Origin Destination  RoundTrip  NbSegments Seg1Departure Seg1Arrival  \\\n",
       "0    TXL         AUH          1           2           TXL         AUH   \n",
       "\n",
       "     Seg1Date Seg1Carrier  Seg1BookingCode Seg2Departure Seg2Arrival  \\\n",
       "0  2013-01-26          D2              NaN           AUH         TXL   \n",
       "\n",
       "     Seg2Date Seg2Carrier  Seg2BookingCode  Seg3Departure  Seg3Arrival  \\\n",
       "0  2013-02-02          D2              NaN            NaN          NaN   \n",
       "\n",
       "   Seg3Date  Seg3Carrier  Seg3BookingCode  Seg4Departure  Seg4Arrival  \\\n",
       "0       NaN          NaN              NaN            NaN          NaN   \n",
       "\n",
       "   Seg4Date  Seg4Carrier  Seg4BookingCode  Seg5Departure  Seg5Arrival  \\\n",
       "0       NaN          NaN              NaN            NaN          NaN   \n",
       "\n",
       "   Seg5Date  Seg5Carrier  Seg5BookingCode  Seg6Departure  Seg6Arrival  \\\n",
       "0       NaN          NaN              NaN            NaN          NaN   \n",
       "\n",
       "   Seg6Date  Seg6Carrier  Seg6BookingCode    From  IsPublishedForNeg  \\\n",
       "0       NaN          NaN              NaN  1ASIWS                  0   \n",
       "\n",
       "   IsFromInternet  IsFromVista                        TerminalID  \\\n",
       "0               0            0  d41d8cd98f00b204e9800998ecf8427e   \n",
       "\n",
       "  InternetOffice  \n",
       "0            FRA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches_check = pd.read_csv('searches.csv', sep= '^', error_bad_lines=False, nrows=1)\n",
    "searches_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Quick Notes:\n",
    "\n",
    "Before taking an action plan I want to check:\n",
    "\n",
    "    1) Q: Difference between act_date and cre_date (bookings). \n",
    "       A: Both are always before brd_time. It seems cre_date is when the account was created or system detected the user for the first time and act_date is when the flight was booked in the system. The reason to make this assumption is that cre_data is always less than act_data and all act_date is from 2013, while some of cre_dates are dated in 2011 or 2012.\n",
    "       \n",
    "    2) Q: Have both datasets all the months of the year 2013? \n",
    "       A: Both datasets have the 12 months of 2013\n",
    "       \n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Action Plan:\n",
    "\n",
    "Information that appears in both datasets:\n",
    "- Search day and booking day: bookings['act_date'], searches ['Date']\n",
    "- Origin and destination: bookings[['dept_port', 'arr_port'], searches[['Origin', 'Destination']]\n",
    "- Boarding time: bookings['brd_time'], searches['Seg1Date']\n",
    "- Pax: bookings['pax'] has to be > 1 as cancelations are not taken into account. People dont cancel through searches.\n",
    "\n",
    "Once data has no duplicates, search_id and booked_id variable will be created to give a \"key\" to each bookings and search. By doing this, once df´s are merged, it is possible to see how many booking ids and search ids are repeated and find a way to deal with them.\n",
    "\n",
    "\n",
    "\n",
    "#### 1. Discard all no needed information:\n",
    "\n",
    "- Drop duplicates\n",
    "- Create search_id and bookings_id varaibles\n",
    "       \n",
    "#### 2. Create both df with the 4 columns\n",
    "\n",
    "#### 3. Change data to correct type and deal with NaN\n",
    "- Change dates to datetime\n",
    "- Find out how many NaN and evaluate if it makes sense TO DO something OR not\n",
    "- Delete spaces for string in iata codes of bookings\n",
    "\n",
    "\n",
    "#### 4. Merge data\n",
    "\n",
    "- Drop duplicates again if necessary\n",
    "- Check if size is the same and data make sense\n",
    "- Add the 1 and 0 to the raw search df\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Plan Execution with Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ORTEGA\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (40,41,42,44) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Sample of 2M rows\n",
    "bookings_raw = pd.read_csv('bookings.csv', sep= '^', error_bad_lines=False, nrows=2000000)\n",
    "searches_raw = pd.read_csv('searches.csv', sep= '^', error_bad_lines=False, nrows=2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates\n",
    "bookings_nodup = bookings_raw.drop_duplicates()\n",
    "searches_nodup = searches_raw.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseting index to follow an order from 0 to nrows\n",
    "bookings_nodup.reset_index(inplace=True)\n",
    "bookings_nodup.drop('index', axis = 1, inplace=True)\n",
    "\n",
    "searches_nodup.reset_index(inplace=True)\n",
    "searches_nodup.drop('index', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding variables(ID): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_nodup['bookings_Id'] = bookings_nodup.index\n",
    "searches_nodup['searches_Id'] = searches_nodup.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting useful columns\n",
    "bookings_cols_nodup = bookings_nodup[['act_date           ','dep_port', 'arr_port','brd_time           ','pax', \"bookings_Id\"]]\n",
    "searches_cols_nodup = searches_nodup[['Date','Origin','Destination','Seg1Date', \"searches_Id\" ]]\n",
    "\n",
    "#bookings with pax>1\n",
    "bookings_cols_nodup = bookings_cols_nodup[bookings_cols_nodup['pax'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NaN\n",
    "bookings_cols_nodup_nonan = bookings_cols_nodup.dropna()\n",
    "searches_cols_nodup_nonan = searches_cols_nodup.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bookings_raw shape =  (2000000, 38) \n",
      "bookings without duplicates =  (1000000, 39) \n",
      "bookings selected columns and no duplicates = (680866, 6) \n",
      "bookings selected columns, no duplicates and no Nan= (680866, 6)\n",
      "\n",
      "searches_raw shape =  (2000000, 45) \n",
      "searches without duplicates =  (388369, 46) \n",
      "searches selected columns and no duplicates = (388369, 5) \n",
      "searches selected columns, no duplicates and no Nan= (387276, 5)\n"
     ]
    }
   ],
   "source": [
    "print('bookings_raw shape = ', bookings_raw.shape,'\\nbookings without duplicates = ', bookings_nodup.shape, '\\nbookings selected columns and no duplicates =', bookings_cols_nodup.shape,'\\nbookings selected columns, no duplicates and no Nan=', bookings_cols_nodup_nonan.shape)\n",
    "print(\"\")\n",
    "print('searches_raw shape = ', searches_raw.shape,'\\nsearches without duplicates = ', searches_nodup.shape, '\\nsearches selected columns and no duplicates =', searches_cols_nodup.shape,'\\nsearches selected columns, no duplicates and no Nan=', searches_cols_nodup_nonan.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing dates to datetime to have same format in both df and delete the hour\n",
    "import datetime as dt\n",
    "#First for the creation date of the booking and search\n",
    "bookings_cols_nodup_nonan['created_date'] = pd.to_datetime(bookings_cols_nodup_nonan['act_date           '], errors='coerce', format='%Y-%m-%d').dt.date\n",
    "searches_cols_nodup_nonan['created_date'] = pd.to_datetime(searches_cols_nodup_nonan['Date'], errors='coerce', format='%Y-%m-%d').dt.date\n",
    "\n",
    "#Second for the boarding time\n",
    "bookings_cols_nodup_nonan['board_date'] = pd.to_datetime(bookings_cols_nodup_nonan['brd_time           '], errors='coerce', format='%Y-%m-%d').dt.date\n",
    "searches_cols_nodup_nonan['board_date'] = pd.to_datetime(searches_cols_nodup_nonan['Seg1Date'], errors='coerce', format='%Y-%m-%d').dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop old columns with dates and pax as we don't need them anymore\n",
    "bookings_datetime = bookings_cols_nodup_nonan.drop(['act_date           ','brd_time           '], axis =1)\n",
    "searches_datetime = searches_cols_nodup_nonan.drop(['Date', 'Seg1Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing column names of bookings to match searches to make the merge easier\n",
    "bookings_datetime['Origin'] = bookings_datetime['dep_port'].str.split(\" \", n = 1, expand = True)[0]\n",
    "bookings_datetime['Destination'] = bookings_datetime['arr_port'].str.split(\" \", n = 1, expand = True)[0]\n",
    "\n",
    "#Droping no needed columns: pax as it is already filtered and the dep_port arr_port\n",
    "bookings_datetime.drop(['pax','dep_port', 'arr_port'], axis = 1, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing column names of searches to make sure\n",
    "searches_datetime['Origin'] = searches_datetime['Origin'].str.split(\" \", n = 1, expand = True)[0]\n",
    "searches_datetime['Destination'] = searches_datetime['Destination'].str.split(\" \", n = 1, expand = True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging both df\n",
    "merged_searches = searches_datetime.merge(bookings_datetime, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>searches_Id</th>\n",
       "      <th>created_date</th>\n",
       "      <th>board_date</th>\n",
       "      <th>bookings_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXL</td>\n",
       "      <td>AUH</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATH</td>\n",
       "      <td>MIL</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICT</td>\n",
       "      <td>SFO</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-08-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RNB</td>\n",
       "      <td>ARN</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OSL</td>\n",
       "      <td>MAD</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-03-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387321</th>\n",
       "      <td>HLZ</td>\n",
       "      <td>BNE</td>\n",
       "      <td>388364</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>2013-10-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387322</th>\n",
       "      <td>PEK</td>\n",
       "      <td>SEL</td>\n",
       "      <td>388365</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>2013-03-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387323</th>\n",
       "      <td>YUL</td>\n",
       "      <td>NCL</td>\n",
       "      <td>388366</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387324</th>\n",
       "      <td>MIA</td>\n",
       "      <td>NCE</td>\n",
       "      <td>388367</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>2013-01-23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387325</th>\n",
       "      <td>BOG</td>\n",
       "      <td>TUL</td>\n",
       "      <td>388368</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387326 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Origin Destination  searches_Id created_date  board_date  bookings_Id\n",
       "0         TXL         AUH            0   2013-01-01  2013-01-26          NaN\n",
       "1         ATH         MIL            1   2013-01-01  2013-01-04          NaN\n",
       "2         ICT         SFO            2   2013-01-01  2013-08-02          NaN\n",
       "3         RNB         ARN            3   2013-01-01  2013-01-02          NaN\n",
       "4         OSL         MAD            4   2013-01-01  2013-03-22          NaN\n",
       "...       ...         ...          ...          ...         ...          ...\n",
       "387321    HLZ         BNE       388364   2013-01-08  2013-10-26          NaN\n",
       "387322    PEK         SEL       388365   2013-01-08  2013-03-22          NaN\n",
       "387323    YUL         NCL       388366   2013-01-08  2013-01-27          NaN\n",
       "387324    MIA         NCE       388367   2013-01-08  2013-01-23          NaN\n",
       "387325    BOG         TUL       388368   2013-01-08  2013-01-15          NaN\n",
       "\n",
       "[387326 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape seraches:  (387276, 5) \n",
      "shape merged:    (387326, 6)\n"
     ]
    }
   ],
   "source": [
    "print('shape seraches: ', searches_datetime.shape, '\\nshape merged:   ', merged_searches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_searches.shape[0]- searches_datetime.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_searches['bookings_Id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if searches are duplicated based on the ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71021     3\n",
       "10943     3\n",
       "289292    2\n",
       "72541     2\n",
       "382728    2\n",
       "         ..\n",
       "85379     1\n",
       "95620     1\n",
       "97669     1\n",
       "91526     1\n",
       "0         1\n",
       "Name: searches_Id, Length: 387276, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_searches['searches_Id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As searches are duplicated, new df is created droping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_searches_nosearchiddup = merged_searches.drop_duplicates(subset=['searches_Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape seraches:                (387276, 5) \n",
      "shape merged no search dup:    (387276, 6)\n"
     ]
    }
   ],
   "source": [
    "print('shape seraches:               ', searches_datetime.shape, '\\nshape merged no search dup:   ', merged_searches_nosearchiddup.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even druplicated searches were deleted, there are still duplicated bookings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576143.0    4\n",
       "722996.0    3\n",
       "525086.0    2\n",
       "746918.0    2\n",
       "958881.0    2\n",
       "           ..\n",
       "866675.0    1\n",
       "867241.0    1\n",
       "108440.0    1\n",
       "434262.0    1\n",
       "98871.0     1\n",
       "Name: bookings_Id, Length: 474, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_searches_nosearchiddup['bookings_Id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not possible to know if one booking corresponds to an specific search, as there are several searches that match the bookings. This gives us duplicated booking ids and when merged, the system doesnt understand which search ID corresponds to the particular bookings ID and gives a value of \"1\" to both search ids. This ends up with duplicate bookings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the same time, it is not possible to have duplicated bookings (1 booking = 1 booking), therefore the decision I made was to delete the duplicated bookings based on the ID. By doing this probably, some booking ids are going to be assigned to a search that didn´t end up booking, but is identical to another one. Adding other variables like exact time or others in both files we could solve this problem in a better way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new df with no booking duplicates to know exactly how many searches were booked (it doesnt detect which ones exactly, but the number should be the correct one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_searches_nosearchiddup_nobookiddup = merged_searches_nosearchiddup.drop_duplicates(subset=['bookings_Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>searches_Id</th>\n",
       "      <th>created_date</th>\n",
       "      <th>board_date</th>\n",
       "      <th>bookings_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXL</td>\n",
       "      <td>AUH</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>RUH</td>\n",
       "      <td>JED</td>\n",
       "      <td>432</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>544420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>DME</td>\n",
       "      <td>BKK</td>\n",
       "      <td>596</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-29</td>\n",
       "      <td>372991.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>JED</td>\n",
       "      <td>RUH</td>\n",
       "      <td>741</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>576143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>DEL</td>\n",
       "      <td>BOM</td>\n",
       "      <td>923</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>233523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347759</th>\n",
       "      <td>CAI</td>\n",
       "      <td>DXB</td>\n",
       "      <td>348719</td>\n",
       "      <td>2013-12-15</td>\n",
       "      <td>2013-12-17</td>\n",
       "      <td>722996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350077</th>\n",
       "      <td>DRS</td>\n",
       "      <td>FCO</td>\n",
       "      <td>351040</td>\n",
       "      <td>2013-12-18</td>\n",
       "      <td>2014-10-16</td>\n",
       "      <td>912562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350341</th>\n",
       "      <td>SFO</td>\n",
       "      <td>TPE</td>\n",
       "      <td>351304</td>\n",
       "      <td>2013-12-18</td>\n",
       "      <td>2014-02-08</td>\n",
       "      <td>495411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350702</th>\n",
       "      <td>DEN</td>\n",
       "      <td>YYZ</td>\n",
       "      <td>351666</td>\n",
       "      <td>2013-12-18</td>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>985652.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353587</th>\n",
       "      <td>RUH</td>\n",
       "      <td>JED</td>\n",
       "      <td>354556</td>\n",
       "      <td>2013-12-21</td>\n",
       "      <td>2013-12-22</td>\n",
       "      <td>752020.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Origin Destination  searches_Id created_date  board_date  bookings_Id\n",
       "0         TXL         AUH            0   2013-01-01  2013-01-26          NaN\n",
       "430       RUH         JED          432   2013-01-01  2013-01-14     544420.0\n",
       "593       DME         BKK          596   2013-01-01  2013-01-29     372991.0\n",
       "737       JED         RUH          741   2013-01-01  2013-01-04     576143.0\n",
       "919       DEL         BOM          923   2013-01-01  2013-01-02     233523.0\n",
       "...       ...         ...          ...          ...         ...          ...\n",
       "347759    CAI         DXB       348719   2013-12-15  2013-12-17     722996.0\n",
       "350077    DRS         FCO       351040   2013-12-18  2014-10-16     912562.0\n",
       "350341    SFO         TPE       351304   2013-12-18  2014-02-08     495411.0\n",
       "350702    DEN         YYZ       351666   2013-12-18  2014-01-06     985652.0\n",
       "353587    RUH         JED       354556   2013-12-21  2013-12-22     752020.0\n",
       "\n",
       "[475 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_searches_nosearchiddup_nobookiddup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of searches that were booked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_searches_nosearchiddup_nobookiddup['bookings_Id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating final df with 1 and 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_searches_nosearchiddup_nobookiddup_nonan = merged_searches_nosearchiddup_nobookiddup.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_searches_nosearchiddup_nobookiddup_nonan['booked 1= yes, 0 = no'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_final_merge = merged_searches_nosearchiddup_nobookiddup_nonan[['searches_Id', 'booked 1= yes, 0 = no']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = searches_nodup.merge(for_final_merge, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing Nan for 0\n",
    "answer['booked 1= yes, 0 = no'].fillna(0, inplace = True)\n",
    "answer['booked 1= yes, 0 = no'] = answer['booked 1= yes, 0 = no'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if results make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474 474\n"
     ]
    }
   ],
   "source": [
    "#Number of searches booked\n",
    "print(sum(answer['booked 1= yes, 0 = no']), merged_searches_nosearchiddup_nobookiddup['bookings_Id'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(388369, 46) (388369, 47)\n"
     ]
    }
   ],
   "source": [
    "# Shape of df\n",
    "print(searches_nodup.shape, answer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Date, Time, TxnCode, OfficeID, Country, Origin, Destination, RoundTrip, NbSegments, Seg1Departure, Seg1Arrival, Seg1Date, Seg1Carrier, Seg1BookingCode, Seg2Departure, Seg2Arrival, Seg2Date, Seg2Carrier, Seg2BookingCode, Seg3Departure, Seg3Arrival, Seg3Date, Seg3Carrier, Seg3BookingCode, Seg4Departure, Seg4Arrival, Seg4Date, Seg4Carrier, Seg4BookingCode, Seg5Departure, Seg5Arrival, Seg5Date, Seg5Carrier, Seg5BookingCode, Seg6Departure, Seg6Arrival, Seg6Date, Seg6Carrier, Seg6BookingCode, From, IsPublishedForNeg, IsFromInternet, IsFromVista, TerminalID, InternetOffice, searches_Id, booked 1= yes, 0 = no]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ORTEGA\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Checking if there are duplicates\n",
    "print(answer[answer['searches_Id'].value_counts() > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>TxnCode</th>\n",
       "      <th>OfficeID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>RoundTrip</th>\n",
       "      <th>NbSegments</th>\n",
       "      <th>Seg1Departure</th>\n",
       "      <th>Seg1Arrival</th>\n",
       "      <th>Seg1Date</th>\n",
       "      <th>Seg1Carrier</th>\n",
       "      <th>Seg1BookingCode</th>\n",
       "      <th>Seg2Departure</th>\n",
       "      <th>Seg2Arrival</th>\n",
       "      <th>Seg2Date</th>\n",
       "      <th>Seg2Carrier</th>\n",
       "      <th>Seg2BookingCode</th>\n",
       "      <th>Seg3Departure</th>\n",
       "      <th>Seg3Arrival</th>\n",
       "      <th>Seg3Date</th>\n",
       "      <th>Seg3Carrier</th>\n",
       "      <th>Seg3BookingCode</th>\n",
       "      <th>Seg4Departure</th>\n",
       "      <th>Seg4Arrival</th>\n",
       "      <th>Seg4Date</th>\n",
       "      <th>Seg4Carrier</th>\n",
       "      <th>Seg4BookingCode</th>\n",
       "      <th>Seg5Departure</th>\n",
       "      <th>Seg5Arrival</th>\n",
       "      <th>Seg5Date</th>\n",
       "      <th>Seg5Carrier</th>\n",
       "      <th>Seg5BookingCode</th>\n",
       "      <th>Seg6Departure</th>\n",
       "      <th>Seg6Arrival</th>\n",
       "      <th>Seg6Date</th>\n",
       "      <th>Seg6Carrier</th>\n",
       "      <th>Seg6BookingCode</th>\n",
       "      <th>From</th>\n",
       "      <th>IsPublishedForNeg</th>\n",
       "      <th>IsFromInternet</th>\n",
       "      <th>IsFromVista</th>\n",
       "      <th>TerminalID</th>\n",
       "      <th>InternetOffice</th>\n",
       "      <th>searches_Id</th>\n",
       "      <th>booked 1= yes, 0 = no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>20:25:57</td>\n",
       "      <td>MPT</td>\n",
       "      <td>624d8c3ac0b3a7ca03e3c167e0f48327</td>\n",
       "      <td>DE</td>\n",
       "      <td>TXL</td>\n",
       "      <td>AUH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TXL</td>\n",
       "      <td>AUH</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>D2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AUH</td>\n",
       "      <td>TXL</td>\n",
       "      <td>2013-02-02</td>\n",
       "      <td>D2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>FRA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10:15:33</td>\n",
       "      <td>MPT</td>\n",
       "      <td>b0af35b31588dc4ab06d5cf2986e8e02</td>\n",
       "      <td>MD</td>\n",
       "      <td>ATH</td>\n",
       "      <td>MIL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ATH</td>\n",
       "      <td>MIL</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>KIV</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>18:04:49</td>\n",
       "      <td>MPT</td>\n",
       "      <td>3561a60621de06ab1badc8ca55699ef3</td>\n",
       "      <td>US</td>\n",
       "      <td>ICT</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ICT</td>\n",
       "      <td>SFO</td>\n",
       "      <td>2013-08-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>ICT</td>\n",
       "      <td>2013-08-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>17:42:40</td>\n",
       "      <td>FXP</td>\n",
       "      <td>1864e5e8013d9414150e91d26b6a558b</td>\n",
       "      <td>SE</td>\n",
       "      <td>RNB</td>\n",
       "      <td>ARN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RNB</td>\n",
       "      <td>ARN</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>DU</td>\n",
       "      <td>W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>STO</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>17:48:29</td>\n",
       "      <td>MPT</td>\n",
       "      <td>1ec336348f44207d2e0027dc3a68c118</td>\n",
       "      <td>NO</td>\n",
       "      <td>OSL</td>\n",
       "      <td>MAD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OSL</td>\n",
       "      <td>MAD</td>\n",
       "      <td>2013-03-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAD</td>\n",
       "      <td>OSL</td>\n",
       "      <td>2013-03-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>OSL</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388364</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>01:54:16</td>\n",
       "      <td>MPT</td>\n",
       "      <td>4337f2104b2ff5bf8ec437c68c5ed20e</td>\n",
       "      <td>NZ</td>\n",
       "      <td>HLZ</td>\n",
       "      <td>BNE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLZ</td>\n",
       "      <td>BNE</td>\n",
       "      <td>2013-10-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>CHC</td>\n",
       "      <td>388364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388365</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>03:38:11</td>\n",
       "      <td>MPT</td>\n",
       "      <td>4b3d2a0a608ccaefbc68d1b9531d7245</td>\n",
       "      <td>HK</td>\n",
       "      <td>PEK</td>\n",
       "      <td>SEL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PEK</td>\n",
       "      <td>SEL</td>\n",
       "      <td>2013-03-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEL</td>\n",
       "      <td>PEK</td>\n",
       "      <td>2013-03-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>HKG</td>\n",
       "      <td>388365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388366</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>21:50:30</td>\n",
       "      <td>MPT</td>\n",
       "      <td>440642a9bdaeb6287f826cefd73255e8</td>\n",
       "      <td>US</td>\n",
       "      <td>YUL</td>\n",
       "      <td>NCL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>YUL</td>\n",
       "      <td>NCL</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>DX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>HPN</td>\n",
       "      <td>388366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388367</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>23:40:20</td>\n",
       "      <td>MPT</td>\n",
       "      <td>e175ff926640d0f543bb15f8b4a88ed0</td>\n",
       "      <td>US</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NCE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NCE</td>\n",
       "      <td>2013-01-23</td>\n",
       "      <td>LK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>LGA</td>\n",
       "      <td>388367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388368</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>18:34:03</td>\n",
       "      <td>MTP</td>\n",
       "      <td>f255adf41703866005024188b78b405d</td>\n",
       "      <td>CO</td>\n",
       "      <td>BOG</td>\n",
       "      <td>TUL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BOG</td>\n",
       "      <td>TUL</td>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>BOG</td>\n",
       "      <td>388368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388369 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date      Time TxnCode                          OfficeID  \\\n",
       "0       2013-01-01  20:25:57     MPT  624d8c3ac0b3a7ca03e3c167e0f48327   \n",
       "1       2013-01-01  10:15:33     MPT  b0af35b31588dc4ab06d5cf2986e8e02   \n",
       "2       2013-01-01  18:04:49     MPT  3561a60621de06ab1badc8ca55699ef3   \n",
       "3       2013-01-01  17:42:40     FXP  1864e5e8013d9414150e91d26b6a558b   \n",
       "4       2013-01-01  17:48:29     MPT  1ec336348f44207d2e0027dc3a68c118   \n",
       "...            ...       ...     ...                               ...   \n",
       "388364  2013-01-08  01:54:16     MPT  4337f2104b2ff5bf8ec437c68c5ed20e   \n",
       "388365  2013-01-08  03:38:11     MPT  4b3d2a0a608ccaefbc68d1b9531d7245   \n",
       "388366  2013-01-08  21:50:30     MPT  440642a9bdaeb6287f826cefd73255e8   \n",
       "388367  2013-01-08  23:40:20     MPT  e175ff926640d0f543bb15f8b4a88ed0   \n",
       "388368  2013-01-08  18:34:03     MTP  f255adf41703866005024188b78b405d   \n",
       "\n",
       "       Country Origin Destination  RoundTrip  NbSegments Seg1Departure  \\\n",
       "0           DE    TXL         AUH        1.0         2.0           TXL   \n",
       "1           MD    ATH         MIL        0.0         1.0           ATH   \n",
       "2           US    ICT         SFO        1.0         2.0           ICT   \n",
       "3           SE    RNB         ARN        0.0         1.0           RNB   \n",
       "4           NO    OSL         MAD        1.0         2.0           OSL   \n",
       "...        ...    ...         ...        ...         ...           ...   \n",
       "388364      NZ    HLZ         BNE        0.0         1.0           HLZ   \n",
       "388365      HK    PEK         SEL        1.0         2.0           PEK   \n",
       "388366      US    YUL         NCL        0.0         1.0           YUL   \n",
       "388367      US    MIA         NCE        0.0         1.0           MIA   \n",
       "388368      CO    BOG         TUL        0.0         1.0           BOG   \n",
       "\n",
       "       Seg1Arrival    Seg1Date Seg1Carrier Seg1BookingCode Seg2Departure  \\\n",
       "0              AUH  2013-01-26          D2             NaN           AUH   \n",
       "1              MIL  2013-01-04         NaN             NaN           NaN   \n",
       "2              SFO  2013-08-02         NaN             NaN           SFO   \n",
       "3              ARN  2013-01-02          DU               W           NaN   \n",
       "4              MAD  2013-03-22         NaN             NaN           MAD   \n",
       "...            ...         ...         ...             ...           ...   \n",
       "388364         BNE  2013-10-26         NaN             NaN           NaN   \n",
       "388365         SEL  2013-03-22         NaN             NaN           SEL   \n",
       "388366         NCL  2013-01-27          DX             NaN           NaN   \n",
       "388367         NCE  2013-01-23          LK             NaN           NaN   \n",
       "388368         TUL  2013-01-15         NaN             NaN           NaN   \n",
       "\n",
       "       Seg2Arrival    Seg2Date Seg2Carrier Seg2BookingCode Seg3Departure  \\\n",
       "0              TXL  2013-02-02          D2             NaN           NaN   \n",
       "1              NaN         NaN         NaN             NaN           NaN   \n",
       "2              ICT  2013-08-09         NaN             NaN           NaN   \n",
       "3              NaN         NaN         NaN             NaN           NaN   \n",
       "4              OSL  2013-03-31         NaN             NaN           NaN   \n",
       "...            ...         ...         ...             ...           ...   \n",
       "388364         NaN         NaN         NaN             NaN           NaN   \n",
       "388365         PEK  2013-03-25         NaN             NaN           NaN   \n",
       "388366         NaN         NaN         NaN             NaN           NaN   \n",
       "388367         NaN         NaN         NaN             NaN           NaN   \n",
       "388368         NaN         NaN         NaN             NaN           NaN   \n",
       "\n",
       "       Seg3Arrival Seg3Date Seg3Carrier Seg3BookingCode Seg4Departure  \\\n",
       "0              NaN      NaN         NaN             NaN           NaN   \n",
       "1              NaN      NaN         NaN             NaN           NaN   \n",
       "2              NaN      NaN         NaN             NaN           NaN   \n",
       "3              NaN      NaN         NaN             NaN           NaN   \n",
       "4              NaN      NaN         NaN             NaN           NaN   \n",
       "...            ...      ...         ...             ...           ...   \n",
       "388364         NaN      NaN         NaN             NaN           NaN   \n",
       "388365         NaN      NaN         NaN             NaN           NaN   \n",
       "388366         NaN      NaN         NaN             NaN           NaN   \n",
       "388367         NaN      NaN         NaN             NaN           NaN   \n",
       "388368         NaN      NaN         NaN             NaN           NaN   \n",
       "\n",
       "       Seg4Arrival Seg4Date Seg4Carrier Seg4BookingCode Seg5Departure  \\\n",
       "0              NaN      NaN         NaN             NaN           NaN   \n",
       "1              NaN      NaN         NaN             NaN           NaN   \n",
       "2              NaN      NaN         NaN             NaN           NaN   \n",
       "3              NaN      NaN         NaN             NaN           NaN   \n",
       "4              NaN      NaN         NaN             NaN           NaN   \n",
       "...            ...      ...         ...             ...           ...   \n",
       "388364         NaN      NaN         NaN             NaN           NaN   \n",
       "388365         NaN      NaN         NaN             NaN           NaN   \n",
       "388366         NaN      NaN         NaN             NaN           NaN   \n",
       "388367         NaN      NaN         NaN             NaN           NaN   \n",
       "388368         NaN      NaN         NaN             NaN           NaN   \n",
       "\n",
       "       Seg5Arrival Seg5Date Seg5Carrier Seg5BookingCode Seg6Departure  \\\n",
       "0              NaN      NaN         NaN             NaN           NaN   \n",
       "1              NaN      NaN         NaN             NaN           NaN   \n",
       "2              NaN      NaN         NaN             NaN           NaN   \n",
       "3              NaN      NaN         NaN             NaN           NaN   \n",
       "4              NaN      NaN         NaN             NaN           NaN   \n",
       "...            ...      ...         ...             ...           ...   \n",
       "388364         NaN      NaN         NaN             NaN           NaN   \n",
       "388365         NaN      NaN         NaN             NaN           NaN   \n",
       "388366         NaN      NaN         NaN             NaN           NaN   \n",
       "388367         NaN      NaN         NaN             NaN           NaN   \n",
       "388368         NaN      NaN         NaN             NaN           NaN   \n",
       "\n",
       "       Seg6Arrival Seg6Date Seg6Carrier Seg6BookingCode    From  \\\n",
       "0              NaN      NaN         NaN             NaN  1ASIWS   \n",
       "1              NaN      NaN         NaN             NaN  1ASIWS   \n",
       "2              NaN      NaN         NaN             NaN  1ASIWS   \n",
       "3              NaN      NaN         NaN             NaN    1ASI   \n",
       "4              NaN      NaN         NaN             NaN  1ASIWS   \n",
       "...            ...      ...         ...             ...     ...   \n",
       "388364         NaN      NaN         NaN             NaN  1ASIWS   \n",
       "388365         NaN      NaN         NaN             NaN    1ASI   \n",
       "388366         NaN      NaN         NaN             NaN  1ASIWS   \n",
       "388367         NaN      NaN         NaN             NaN    1ASI   \n",
       "388368         NaN      NaN         NaN             NaN  1ASIWS   \n",
       "\n",
       "       IsPublishedForNeg IsFromInternet IsFromVista  \\\n",
       "0                      0              0           0   \n",
       "1                      0              0           0   \n",
       "2                      0              0           0   \n",
       "3                      0              0           0   \n",
       "4                      0              0           0   \n",
       "...                  ...            ...         ...   \n",
       "388364                 0              0           0   \n",
       "388365                 0              0           0   \n",
       "388366                 0              0           0   \n",
       "388367                 0              0           0   \n",
       "388368                 0              0           0   \n",
       "\n",
       "                              TerminalID InternetOffice  searches_Id  \\\n",
       "0       d41d8cd98f00b204e9800998ecf8427e            FRA            0   \n",
       "1       d41d8cd98f00b204e9800998ecf8427e            KIV            1   \n",
       "2       d41d8cd98f00b204e9800998ecf8427e            NYC            2   \n",
       "3       d41d8cd98f00b204e9800998ecf8427e            STO            3   \n",
       "4       d41d8cd98f00b204e9800998ecf8427e            OSL            4   \n",
       "...                                  ...            ...          ...   \n",
       "388364  d41d8cd98f00b204e9800998ecf8427e            CHC       388364   \n",
       "388365  d41d8cd98f00b204e9800998ecf8427e            HKG       388365   \n",
       "388366  d41d8cd98f00b204e9800998ecf8427e            HPN       388366   \n",
       "388367  d41d8cd98f00b204e9800998ecf8427e            LGA       388367   \n",
       "388368  d41d8cd98f00b204e9800998ecf8427e            BOG       388368   \n",
       "\n",
       "        booked 1= yes, 0 = no  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "...                       ...  \n",
       "388364                      0  \n",
       "388365                      0  \n",
       "388366                      0  \n",
       "388367                      0  \n",
       "388368                      0  \n",
       "\n",
       "[388369 rows x 47 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Plan Execution with All Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_data_result(bookings_data,searches_data):\n",
    "\n",
    "    bookings_raw = pd.read_csv('bookings.csv', sep= '^', error_bad_lines=False)\n",
    "    searches_raw = pd.read_csv('searches.csv', sep= '^', error_bad_lines=False)\n",
    "\n",
    "    #Drop duplicates\n",
    "    bookings_nodup = bookings_raw.drop_duplicates()\n",
    "    searches_nodup = searches_raw.drop_duplicates()\n",
    "\n",
    "    # Reseting index to follow an order from 0 to nrows\n",
    "    bookings_nodup.reset_index(inplace=True)\n",
    "    bookings_nodup.drop('index', axis = 1, inplace=True)\n",
    "\n",
    "    searches_nodup.reset_index(inplace=True)\n",
    "    searches_nodup.drop('index', axis = 1, inplace=True)\n",
    "    \n",
    "    #Adding variables:\n",
    "    bookings_nodup['bookings_Id'] = bookings_nodup.index\n",
    "    searches_nodup['searches_Id'] = searches_nodup.index\n",
    "\n",
    "    #Selecting useful columns\n",
    "    bookings_cols_nodup = bookings_nodup[['act_date           ','dep_port', 'arr_port','brd_time           ','pax', \"bookings_Id\"]]\n",
    "    searches_cols_nodup = searches_nodup[['Date','Origin','Destination','Seg1Date', \"searches_Id\" ]]\n",
    "\n",
    "    #bookings with pax>1\n",
    "    bookings_cols_nodup = bookings_cols_nodup[bookings_cols_nodup['pax'] > 0]\n",
    "\n",
    "    #Drop NaN\n",
    "    bookings_cols_nodup_nonan = bookings_cols_nodup.dropna()\n",
    "    searches_cols_nodup_nonan = searches_cols_nodup.dropna()\n",
    "\n",
    "    print('bookings_raw shape = ', bookings_raw.shape,'\\nbookings without duplicates = ', bookings_nodup.shape, '\\nbookings selected columns and no duplicates =', bookings_cols_nodup.shape,'\\nbookings selected columns, no duplicates and no Nan=', bookings_cols_nodup_nonan.shape)\n",
    "    print(\"\")\n",
    "    print('searches_raw shape = ', searches_raw.shape,'\\nsearches without duplicates = ', searches_nodup.shape, '\\nsearches selected columns and no duplicates =', searches_cols_nodup.shape,'\\nsearches selected columns, no duplicates and no Nan=', searches_cols_nodup_nonan.shape)  \n",
    "\n",
    "    # Changing dates to datetime to have same format in both df and delete the hour\n",
    "    import datetime as dt\n",
    "    #First for the creation date of the booking and search\n",
    "    bookings_cols_nodup_nonan['created_date'] = pd.to_datetime(bookings_cols_nodup_nonan['act_date           '], errors='coerce', format='%Y-%m-%d').dt.date\n",
    "    searches_cols_nodup_nonan['created_date'] = pd.to_datetime(searches_cols_nodup_nonan['Date'], errors='coerce', format='%Y-%m-%d').dt.date\n",
    "\n",
    "    #Second for the boarding time\n",
    "    bookings_cols_nodup_nonan['board_date'] = pd.to_datetime(bookings_cols_nodup_nonan['brd_time           '], errors='coerce', format='%Y-%m-%d').dt.date\n",
    "    searches_cols_nodup_nonan['board_date'] = pd.to_datetime(searches_cols_nodup_nonan['Seg1Date'], errors='coerce', format='%Y-%m-%d').dt.date\n",
    "\n",
    "\n",
    "    #Drop old columns with dates and pax as we don't need them anymore\n",
    "    bookings_datetime = bookings_cols_nodup_nonan.drop(['act_date           ','brd_time           '], axis =1)\n",
    "    searches_datetime = searches_cols_nodup_nonan.drop(['Date', 'Seg1Date'], axis = 1)\n",
    "\n",
    "    #Changing column names of bookings to match searches to make the merge easier\n",
    "    bookings_datetime['Origin'] = bookings_datetime['dep_port'].str.split(\" \", n = 1, expand = True)[0]\n",
    "    bookings_datetime['Destination'] = bookings_datetime['arr_port'].str.split(\" \", n = 1, expand = True)[0]\n",
    "\n",
    "    #Droping no needed columns: pax as it is already filtered and the dep_port arr_port\n",
    "    bookings_datetime.drop(['pax','dep_port', 'arr_port'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "    #Changing column names of searches to make sure\n",
    "    searches_datetime['Origin'] = searches_datetime['Origin'].str.split(\" \", n = 1, expand = True)[0]\n",
    "    searches_datetime['Destination'] = searches_datetime['Destination'].str.split(\" \", n = 1, expand = True)[0]\n",
    "\n",
    "\n",
    "    #Lets try to join it with searches at the left\n",
    "\n",
    "    #Merging both df\n",
    "    merged_searches = searches_datetime.merge(bookings_datetime, how = 'left')\n",
    "\n",
    "\n",
    "    merged_searches_nosearchiddup = merged_searches.drop_duplicates(subset=['searches_Id'])\n",
    "\n",
    "\n",
    "    merged_searches_nosearchiddup_nobookiddup = merged_searches_nosearchiddup.drop_duplicates(subset=['bookings_Id'])\n",
    "\n",
    "    #Creating final df with 1 and 0:\n",
    "\n",
    "    merged_searches_nosearchiddup_nobookiddup_nonan = merged_searches_nosearchiddup_nobookiddup.dropna()\n",
    "\n",
    "    merged_searches_nosearchiddup_nobookiddup_nonan['booked 1= yes, 0 = no'] = 1\n",
    "\n",
    "    for_final_merge = merged_searches_nosearchiddup_nobookiddup_nonan[['searches_Id', 'booked 1= yes, 0 = no']]\n",
    "\n",
    "    answer = searches_nodup.merge(for_final_merge, how='left')\n",
    "\n",
    "    #Changing Nan for 0\n",
    "    answer['booked 1= yes, 0 = no'].fillna(0, inplace = True)\n",
    "    answer['booked 1= yes, 0 = no'] = answer['booked 1= yes, 0 = no'].astype(int)\n",
    "\n",
    "    #Number of searches booked\n",
    "    print(sum(answer['booked 1= yes, 0 = no']), merged_searches_nosearchiddup_nobookiddup['bookings_Id'].count())\n",
    "\n",
    "    # Shape of df\n",
    "    print(searches_nodup.shape, answer.shape)\n",
    "\n",
    "    #Checking if there are duplicates\n",
    "    print(answer[answer['searches_Id'].value_counts() > 1])\n",
    "\n",
    "    return(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "all_data_result('bookings.csv', 'searches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
